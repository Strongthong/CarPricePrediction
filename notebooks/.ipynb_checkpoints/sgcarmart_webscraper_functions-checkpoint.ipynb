{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_url = \"https://www.sgcarmart.com/used_cars/info.php?ID=862831&DL=3417\"\n",
    "response2 = requests.get(listing_url)\n",
    "response2.status_code\n",
    "page2 = response2.text\n",
    "main_page2 = BeautifulSoup(page2, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing URL Grabber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title/Brand Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mercedes-Benz\n",
      "Isuzu\n"
     ]
    }
   ],
   "source": [
    "# Define a function to retrieve car brand name given a listing url\n",
    "\n",
    "def brand_retrieval(listing_url):\n",
    "    import time \n",
    "    response = requests.get(listing_url)\n",
    "    parsed_listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    brand_name = parsed_listing_url.find(class_='link_redbanner').text.split()[0]\n",
    "    \n",
    "    time.sleep(1)\n",
    "    return brand_name\n",
    "\n",
    "\n",
    "print(brand_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862832&DL=2934'))\n",
    "print(brand_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862874&DL=2854'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69955\n",
      "42800\n"
     ]
    }
   ],
   "source": [
    "def price_retrieval(listing_url):\n",
    "    import time\n",
    "    response = requests.get(listing_url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    data_value = soup.find_all(class_='font_red')[0].text.strip()\n",
    "    data_value = data_value.split('$')\n",
    "\n",
    "    price = price_error_handling(data_value)\n",
    "    time.sleep(1)\n",
    "    return price\n",
    "\n",
    "\n",
    "def price_error_handling(data_value):\n",
    "    # Try-Exception error handling\n",
    "    \n",
    "    try:   # First try to deal with values higher than 1000\n",
    "        price = data_value[1]  # will fail on IndexError if retrieves ['na'] scenario\n",
    "        price = int(price.split(',')[0] + price.split(',')[1]) # Will fail on IndexError if tries to split '900' with a ',' in ['',900]\n",
    "        \n",
    "    except IndexError:  # Dealing with ['na'] and ['', 900'] scenarios\n",
    "        try: \n",
    "            price = int(data_value[1]) # Will fail on IndexError if ['na'] scenario\n",
    "        except IndexError:  # Deals with ['na'] scenarios\n",
    "            price = np.nan  # Stores NA values as nan\n",
    "    \n",
    "    return price\n",
    "\n",
    "print(price_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862832&DL=2934'))\n",
    "print(price_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862874&DL=2854'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depreciation Value Per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4450\n",
      "6500\n"
     ]
    }
   ],
   "source": [
    "# Define a function that retrieves depreciation value per year given a listing url\n",
    "def depreciation_value_per_year_error_handler(data_value):\n",
    "    if len(data_value) < 2:\n",
    "        data_value = np.nan\n",
    "\n",
    "    else: \n",
    "        try:                 \n",
    "            desired_value = int(data_value[0].split(',')[0] +\\\n",
    "                                data_value[0].split(',')[1]) # Will fail on IndexError if tries to split '900' with a ',' in ['900','']\n",
    "        except IndexError: \n",
    "            desired_value = int(data_value[0])\n",
    "        \n",
    "        return desired_value\n",
    "    \n",
    "def depreciation_value_per_year_retrieval(listing_url):\n",
    "    response = requests.get(listing_url)\n",
    "    parsed_listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    data_value = parsed_listing_url.find_all(class_=\"label\")[1].findNextSibling().text.strip().split('$')[1].split('/yr')\n",
    "    \n",
    "    depreciation_value_per_year = depreciation_value_per_year_error_handler(data_value)\n",
    "    \n",
    "    return depreciation_value_per_year\n",
    "\n",
    "print(depreciation_value_per_year_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862831&DL=3417'))\n",
    "print(depreciation_value_per_year_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862874&DL=2854'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road Tax/Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "974\n"
     ]
    }
   ],
   "source": [
    "# Define a function to retrieve road tax /yr given a listing url\n",
    "def road_tax_retrieval(listing_url):\n",
    "    import time\n",
    "    response = requests.get(listing_url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    \n",
    "    string_data = soup.find_all(class_='row_info')[1].text.strip()\n",
    "    road_tax_yearly = road_tax_error_handler(string_data)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    return road_tax_yearly\n",
    "    \n",
    "\n",
    "def road_tax_error_handler(string_data):\n",
    "    if '/yr' in string_data: # Only takes in scenarios that are not NA\n",
    "        try:\n",
    "            # Removes '$\" character and splits string_data into a list of ['', 1,000] or ['', 900]\n",
    "            road_tax_per_year = \\\n",
    "            string_data.replace('/yr','').strip().split('$') \n",
    "\n",
    "            # Accesses the second item in the list\n",
    "            road_tax_per_year = road_tax_per_year[1] \n",
    "\n",
    "\n",
    "            road_tax_per_year = int(road_tax_per_year.split(',')[0] +\\\n",
    "                                    road_tax_per_year.split(',')[1])  # Will fail on IndexError if value is above 1000\n",
    "\n",
    "        except IndexError: # Handles values that are below 1000. (i.e. ['',900])\n",
    "            road_tax_pear_year = int(road_tax_per_year[1])\n",
    "\n",
    "    else: # Deals with 'NA' scenario\n",
    "        road_tax_per_year = np.nan\n",
    "    \n",
    "    return road_tax_per_year\n",
    "        \n",
    "print(road_tax_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862874&DL=2854'))\n",
    "print(road_tax_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862832&DL=2934'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registered Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-May-2016\n",
      "27-Oct-2009\n"
     ]
    }
   ],
   "source": [
    "# Define function to retrieve Registered date given a parsed listing url\n",
    "\n",
    "# url to parse from \"https://www.sgcarmart.com/used_cars/info.php?ID=862816&DL=2397\"\n",
    "# listing_url = \"https://www.sgcarmart.com/used_cars/info.php?ID=862831&DL=3417\"\n",
    "# response2 = requests.get(listing_url)\n",
    "# page2 = response2.text\n",
    "# parsed_listing_url = BeautifulSoup(page2, 'lxml')\n",
    "\n",
    "def registered_date_retrieval(listing_url):\n",
    "    import time\n",
    "    response = requests.get(listing_url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    \n",
    "    reg_date = soup.find_all(class_='row_bg')[1].find_all('td')[3].text.split()[0].split('(')[0]\n",
    "    \n",
    "    time.sleep(1)\n",
    "    return reg_date\n",
    "\n",
    "print(registered_date_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862874&DL=2854'))\n",
    "print(registered_date_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862832&DL=2934'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Days of COE Left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2379\n",
      "3472\n"
     ]
    }
   ],
   "source": [
    "# Define a function to retrieve days of COE left in terms of days:\n",
    "\n",
    "# Retrieve into usable format for link\n",
    "def days_of_coe_retrieval(listing_url):\n",
    "    \"\"\"Takes in a listing page (individual cars) and retrieve the days of COE left\n",
    "    ---\n",
    "    Input: str\n",
    "    Output: Days of COE left in integer form\n",
    "    \"\"\"\n",
    "    import time\n",
    "    response = requests.get(listing_url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    \n",
    "    days_of_coe_left_yy_mm_dd_format_for_cleaner_function=\\\n",
    "    soup.find_all(class_='row_bg')[1].find_all('td')[3].text.split('(')[1].split('COE')[0].strip()\n",
    "    \n",
    "    time.sleep(1)\n",
    "    return yr_mm_dd_cleaner(days_of_coe_left_yy_mm_dd_format_for_cleaner_function)\n",
    "\n",
    "\n",
    "# Define a function to calculate days of COE left\n",
    "def yr_mm_dd_cleaner(str1):\n",
    "    \"\"\"Accepts a string that may or may include the elements yr mths days and \n",
    "    converts the whole string into number of days.\n",
    "    ----\n",
    "    Input: single string\n",
    "    output: number of days in integer form\n",
    "    ----\n",
    "    Example string inputs:\n",
    "    - 4yrs 2mths 23days\n",
    "    - 5yrs\n",
    "    - 2 mths 23 days\n",
    "    - 50 days\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert days_of_coe_left_yy_mm_dd to days    \n",
    "    year_index = str1.find('yr')\n",
    "    if year_index == -1:\n",
    "        year = 0\n",
    "    else:\n",
    "        year = int(str1[year_index-1])\n",
    "\n",
    "        \n",
    "    mth_index = str1.find('mth')\n",
    "    if mth_index == -1:\n",
    "        mth = 0\n",
    "    else:\n",
    "        mth = int(str1[mth_index-1])\n",
    "\n",
    "        \n",
    "    day_index = str1.find('day')\n",
    "    if day_index == -1:\n",
    "        day = 0\n",
    "    else:\n",
    "        day = int(str1[day_index-1])\n",
    "       \n",
    "    days_of_coe_left = (year * 365) + (mth * 30) + day \n",
    "    return days_of_coe_left\n",
    "\n",
    "print(days_of_coe_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862874&DL=2854'))\n",
    "print(days_of_coe_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862832&DL=2934'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mileage in km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "115000\n"
     ]
    }
   ],
   "source": [
    "# Write a function to retrieve the mileage in km from a listjng url\n",
    "\n",
    "def mileage_error_handler(data_value):\n",
    "    if len(data_value) < 2:  # Deals with ['na'] scenarios\n",
    "        mileage_km = np.nan  # Stores NA values as nan\n",
    "\n",
    "    else:  \n",
    "        try:                 \n",
    "            mileage_km = int(data_value[0].strip().split(',')[0] + data_value[0].strip().split(',')[1])\n",
    "        except IndexError: # Will fail on IndexError if tries to split '900' with a ',' in ['',900]\n",
    "            mileage_km = int(data_value[0].strip())\n",
    "    \n",
    "    return mileage_km\n",
    "\n",
    "def mileage_retrieval(listing_url):\n",
    "    import time\n",
    "    response = requests.get(listing_url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    \n",
    "    data_value = soup.find_all(class_='row_info')[0].text.strip()\n",
    "    data_value = data_value.split('km')\n",
    "    mileage_km = mileage_error_handler(data_value)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    return mileage_km\n",
    "     \n",
    "print(mileage_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862874&DL=2854')) \n",
    "print(mileage_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862832&DL=2934'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manufactured Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n",
      "2009\n"
     ]
    }
   ],
   "source": [
    "# Define a function that returns the manufactured date using a parsed html\n",
    "def manufactured_year_retrieval(listing_url):\n",
    "    import time\n",
    "    response = requests.get(listing_url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    \n",
    "    manufactured_year = soup.find_all(class_='row_info')[6].text\n",
    "    \n",
    "    time.sleep(1)\n",
    "    return manufactured_year\n",
    "\n",
    "print(manufactured_year_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862874&DL=2854'))\n",
    "print(manufactured_year_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862832&DL=2934'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual\n",
      "Auto\n"
     ]
    }
   ],
   "source": [
    "# Define a function that returns the transmission based on a parsed listing url\n",
    "\n",
    "def transmission_retrieval(listing_url):\n",
    "    import time\n",
    "    response = requests.get(listing_url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    \n",
    "    transmission = soup.find_all(class_='row_info')[7].text\n",
    "    \n",
    "    time.sleep(1)\n",
    "    return transmission\n",
    "\n",
    "print(transmission_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862874&DL=2854'))\n",
    "print(transmission_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862832&DL=2934'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dereg Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27850\n",
      "33733\n"
     ]
    }
   ],
   "source": [
    "# Write a function to retrieve dereg value from a parsed url\n",
    "\n",
    "def dereg_value_retrieval(listing_url):\n",
    "    import time\n",
    "    response = requests.get(listing_url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    \n",
    "    # Splits into ['NA'], or ['$11,026', 'as', 'of', 'today', '(change)'] or ['$900', 'as', 'of', 'today', '(change)']\n",
    "    data_value = soup.find_all(class_='row_info')[2].text.strip().split() \n",
    "    \n",
    "    dereg_value_from_scrape_date = dereg_value_error_handler(data_value)\n",
    "    time.sleep(1)\n",
    "    return dereg_value_from_scrape_date\n",
    "    \n",
    "\n",
    "def dereg_value_error_handler(data_value):\n",
    "    if len(data_value) < 2:  # Deals with ['NA'] scenario\n",
    "        dereg_value_from_scrape_date = np.nan\n",
    "\n",
    "    else: \n",
    "        data_value = data_value[0].split('$')[1] # Puts input into '11,026' or '900' format\n",
    "        try:                 \n",
    "            dereg_value_from_scrape_date = \\\n",
    "            int(data_value.split(',')[0] +\\\n",
    "                data_value.split(',')[1]) # Will fail on IndexError if tries to split '900' with a ',' in ['',900]\n",
    "        except IndexError: \n",
    "            dereg_value_from_scrape_date = int(data_value.strip())\n",
    "\n",
    "        return dereg_value_from_scrape_date\n",
    "    \n",
    "print(dereg_value_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862874&DL=2854'))\n",
    "print(dereg_value_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862832&DL=2934'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OMV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30804\n",
      "30804\n"
     ]
    }
   ],
   "source": [
    "# Define a function that retrieves omv based on a parsed listing url\n",
    "def omv_error_handler(data_value):\n",
    "    if len(data_value) < 2:  # deals iwth ['NA'] input\n",
    "        omv = np.nan\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            omv = int(data_value[1].split(',')[0] +\\\n",
    "                      data_value[1].split(',')[1])  # Will fail on index error if try to split 900\n",
    "        except IndexError:\n",
    "            omv = int(data_value[1])\n",
    "    return omv\n",
    "\n",
    "\n",
    "def omv_retrieval(listing_url):\n",
    "    import time\n",
    "    response = requests.get(listing_url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    \n",
    "    data_value = soup.find_all(class_='row_info')[8].text.split('$') \n",
    "    # Splits data into ['', '21,967'], ['','900'] or ['NA'] format for input into error function\n",
    "    \n",
    "    omv = omv_error_handler(data_value)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    return omv     \n",
    "\n",
    "print(omv_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862874&DL=2854'))\n",
    "print(omv_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862874&DL=2854'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1541\n",
      "56913\n"
     ]
    }
   ],
   "source": [
    "# Write a function that retrieves ARF based on a parsed listing url\n",
    "def error_handler(data_value):\n",
    "    if len(data_value) < 2:  # deals iwth ['NA'] input\n",
    "        desired_value = np.nan\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            desired_value = int(data_value[1].split(',')[0] +\\\n",
    "                                data_value[1].split(',')[1])   # Will fail on index error if try to split 900\n",
    "        except IndexError:\n",
    "            desired_value = int(data_value[1])\n",
    "    return desired_value\n",
    "\n",
    "\n",
    "def arf_retrieval(listing_url):\n",
    "    import time\n",
    "    response = requests.get(listing_url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    \n",
    "    data_value = soup.find_all(class_='row_info')[9].text.split('$')\n",
    "    arf = error_handler(data_value)\n",
    "    return arf\n",
    "\n",
    "print(arf_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862874&DL=2854'))\n",
    "print(arf_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862832&DL=2934'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COE Price as of Today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35411\n",
      "42302\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "# Write a function to retrieve COE as of today from a parsed listing url\n",
    "def coe_error_handler(data_value):\n",
    "    if len(data_value) < 2:  # deals iwth ['NA'] input\n",
    "        coe_from_scrape_date = np.nan\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            coe_from_scrape_date = int(data_value[1].split(',')[0] +\\\n",
    "                                       data_value[1].split(',')[1])  # Will fail on index error if try to split 900\n",
    "        except IndexError:\n",
    "            coe_from_scrape_date = int(data_value[1])\n",
    "    return coe_from_scrape_date\n",
    "\n",
    "\n",
    "def coe_retrieval(listing_url):\n",
    "    import time\n",
    "    response = requests.get(listing_url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    \n",
    "    data_value = soup.find_all(class_='row_info')[3].text.split('$')\n",
    "    \n",
    "    coe_from_scrape_date = coe_error_handler(data_value)\n",
    "    time.sleep(1)\n",
    "    return coe_from_scrape_date\n",
    "    \n",
    "print(coe_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862832&DL=2934'))\n",
    "print(coe_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862874&DL=2854'))\n",
    "print(coe_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862869&DL=2976'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engine Capacity (CC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1461\n",
      "1796\n"
     ]
    }
   ],
   "source": [
    "def engine_capacity_error_handler(data_value):\n",
    "    if len(data_value) < 2:  # deals iwth ['NA'] input\n",
    "        desired_value = np.nan\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            desired_value = int(data_value[0].split(',')[0] +\\\n",
    "                                       data_value[0].split(',')[1])  # Will fail on index error if try to split 900\n",
    "        except IndexError:\n",
    "            desired_value = int(data_value[0])\n",
    "    return desired_value\n",
    "\n",
    "\n",
    "def engine_capacity_retrieval(listing_url):\n",
    "    import time\n",
    "    response = requests.get(listing_url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    \n",
    "    data_value = soup.find_all(class_='row_info')[4].text.strip().split('cc')\n",
    "    engine_capacity = engine_capacity_error_handler(data_value)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    return engine_capacity\n",
    "\n",
    "\n",
    "\n",
    "print(engine_capacity_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862869&DL=2976'))\n",
    "print(engine_capacity_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862832&DL=2934'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power (kW) Something to consider for the future. No time already\n",
    "refer to car_webscraper if you want to work on it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curb Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "1615\n"
     ]
    }
   ],
   "source": [
    "def curb_weight_error_handler(data_value):\n",
    "    if len(data_value) < 2:  # deals iwth ['NA'] input\n",
    "        desired_value = np.nan\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            desired_value = int(data_value[0].split(',')[0] +\\\n",
    "                                       data_value[0].split(',')[1])  # Will fail on index error if try to split 900\n",
    "        except IndexError:\n",
    "            desired_value = int(data_value[0])\n",
    "    return desired_value\n",
    "\n",
    "\n",
    "def curb_weight_retrieval(listing_url):\n",
    "    import time\n",
    "    response = requests.get(listing_url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    \n",
    "    data_value = soup.find_all(class_='row_info')[5].text.split()\n",
    "    curb_weight = curb_weight_error_handler(data_value)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    return curb_weight\n",
    "\n",
    "\n",
    "print(curb_weight_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862874&DL=2854'))\n",
    "print(curb_weight_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862832&DL=2934'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No. Of Owners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Define a function to retrieve the no of owners from a parsed listing url\n",
    "def number_of_owners_retrieval(listing_url):\n",
    "    import time\n",
    "    response = requests.get(listing_url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    \n",
    "    no_of_owners = int(soup.find_all(class_='row_info')[-1].text)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    return no_of_owners\n",
    "\n",
    "print(number_of_owners_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862874&DL=2854'))\n",
    "print(number_of_owners_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862832&DL=2934'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type of Vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truck\n",
      "Luxury Sedan\n"
     ]
    }
   ],
   "source": [
    "# Define a function that returns the type of vehicle given a parsed listing url\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def type_of_vehicle_retrieval(listing_url):\n",
    "    import time\n",
    "    response = requests.get(listing_url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    \n",
    "    type_of_vehicle = soup.find(class_='row_bg1').find_all('a')[0].text\n",
    "    \n",
    "    time.sleep(1)    \n",
    "    return type_of_vehicle\n",
    "\n",
    "print(type_of_vehicle_retrieval('https://www.sgcarmart.com/used_cars/info.php?ID=862874&DL=2854'))\n",
    "print(type_of_vehicle_retrieval(\"https://www.sgcarmart.com/used_cars/info.php?ID=862832&DL=2934\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # HTML Grabber code\n",
    "\n",
    "# url = \"https://www.sgcarmart.com/used_cars/listing.php?BRSR=&RPG=100&AVL=2&VEH=2\"\n",
    "\n",
    "# # Base url, or you can think of this as the individual car listing prefix\n",
    "# base_url = 'https://www.sgcarmart.com/used_cars/'\n",
    "\n",
    "# # Make a request to the website and get the object\n",
    "# content = requests.get(url)\n",
    "\n",
    "# # Parse the HTML text\n",
    "# soup = BeautifulSoup(content.text,'lxml')\n",
    "\n",
    "# # Find every single URL in the webpage , refer to this post: \n",
    "# # https://stackoverflow.com/questions/46490626/getting-all-links-from-a-page-beautiful-soup\n",
    "# # This returns a list of every tag that contains a link in the webpage\n",
    "# links = soup.find_all('a')\n",
    "\n",
    "# # Create holder for each individual car listing url in a main url\n",
    "# listing_urls = []\n",
    "\n",
    "# for link in links:\n",
    "#     # Get the link\n",
    "#     suffix = link.get('href')\n",
    "\n",
    "#     # Check if 'ID=' and 'DL=' exist in the string\n",
    "#     if ('ID=' in suffix) and ('DL=' in suffix):\n",
    "#         # Concatenate the two strings if they do\n",
    "#         listing_url = base_url + suffix\n",
    "#         # Append result to the list\n",
    "#         listing_urls.append(listing_url)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def listing_html_grabber(url):\n",
    "#     \"\"\"Returns a list of 100 individual listings per main url\n",
    "#     ---\n",
    "#     input: Requires a url to scrape from: \n",
    "#     eg: url = 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=0&RPG=100&AVL=2&VEH=2'\n",
    "    \n",
    "#     output: a list of 100 individual listings per main url\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Base url, or you can think of this as the individual car listing prefix\n",
    "#     base_url = 'https://www.sgcarmart.com/used_cars/'\n",
    "    \n",
    "#     # Make a request to the website and get the object\n",
    "#     content = requests.get(url)\n",
    "\n",
    "#     # Parse the HTML text\n",
    "#     soup = BeautifulSoup(content.text, 'lxml')\n",
    "\n",
    "#     # Find every single URL in the webpage , refer to this post: \n",
    "#     # https://stackoverflow.com/questions/46490626/getting-all-links-from-a-page-beautiful-soup\n",
    "#     # This returns a list of every tag that contains a link in the webpage\n",
    "#     links = soup.find_all('a')\n",
    "    \n",
    "#     # Create a list for storing all the individual listing urls\n",
    "#     listing_urls = []\n",
    "    \n",
    "\n",
    "#     for link in links:\n",
    "#         # Get the link\n",
    "#         suffix = link.get('href')\n",
    "\n",
    "#         # Check if 'ID=' and 'DL=' exist in the string\n",
    "#         if ('ID=' in suffix) and ('DL=' in suffix):\n",
    "\n",
    "#             # Concatenate the two strings if they do\n",
    "#             listing_url = base_url + suffix\n",
    "#             # Append result to the list\n",
    "#             llsting_urls.append(listing_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of main pages to iterate through\n",
    "main_page_listing_list = []\n",
    "for idx, link in enumerate(range(40)):\n",
    "    url = \"https://www.sgcarmart.com/used_cars/listing.php?BRSR=\" + str(idx * 100) + \"&RPG=100&AVL=2&VEH=2\"\n",
    "    main_page_listing_list.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.sgcarmart.com/used_cars/listing.php?BRSR=0&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=100&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=200&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=300&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=400&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=500&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=600&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=700&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=800&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=900&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1000&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1100&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1200&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1300&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1400&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1500&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1600&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1700&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1800&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1900&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2000&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2100&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2200&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2300&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2400&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2500&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2600&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2700&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2800&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2900&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=3000&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=3100&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=3200&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=3300&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=3400&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=3500&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=3600&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=3700&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=3800&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=3900&RPG=100&AVL=2&VEH=2'] \n",
      " \n",
      " 40\n"
     ]
    }
   ],
   "source": [
    "print(main_page_listing_list,'\\n','\\n', len(main_page_listing_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving individual listing urls from main pages of 100 listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base url, or you can think of this as the individual car listing prefix\n",
    "base_url = 'https://www.sgcarmart.com/used_cars/'\n",
    "listing_urls = []\n",
    "\n",
    "# Acquiring indvidual car listings    \n",
    "for main_link in main_page_listing_list:\n",
    "   \n",
    "    # Make a request to the website and get the object\n",
    "    content = requests.get(main_link)\n",
    "\n",
    "    # Parse the HTML text\n",
    "    soup = BeautifulSoup(content.text, 'lxml')\n",
    "\n",
    "    # Find every single URL in the webpage , refer to this post: # https://stackoverflow.com/questions/46490626/getting-all-links-from-a-page-beautiful-soup\n",
    "    # This returns a list of every tag that contains a link in one main link (each element in main page listing)\n",
    "    links = soup.find_all('a')\n",
    "    \n",
    "    # Create a list for storing all the individual listing urls\n",
    "    \n",
    "    for link in links:\n",
    "        # Get link in <a href>\n",
    "        suffix = link.get('href')\n",
    "\n",
    "        # Check if 'ID=' and 'DL=' exist in the string\n",
    "        if ('ID=' in suffix) and ('DL=' in suffix):\n",
    "\n",
    "            # Concatenate the two strings if they do\n",
    "            listing_url = base_url + suffix\n",
    "            \n",
    "            # Append result to the list\n",
    "            listing_urls.append(listing_url)\n",
    "            \n",
    "#     Removing duplicates\n",
    "    set_listing_urls = set(listing_urls)\n",
    "    listing_urls = list(set_listing_urls)\n",
    "    \n",
    "    # Prevent oneself from getting blocked from the website\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3997\n",
      "3997\n",
      "3997\n"
     ]
    }
   ],
   "source": [
    "print(len(listing_urls))\n",
    "print(len(set(listing_urls)))\n",
    "print(len(list(set(listing_urls))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_scraper(listing_url_list):\n",
    "    \"\"\"Accepts a list of individual car listing urls and returns variables of importance for linear regression analysis.\n",
    "    ---\n",
    "    Input: List of urls\n",
    "    Output: Variables\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieval functions\n",
    "    print(f\"Brand: {brand_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Price: {price_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Depreciation Value Per Year: {depreciation_value_per_year_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Registered Date: {registered_date_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Mileage (km): {mileage_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Manufactured Year: {manufactured_year_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Road Tax Per Year:{road_tax_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Transmission: {transmission_retrieval(listing_url)}\\n\")\n",
    "    print(\"Dereg Value as of {}: {}\".format(datetime.now().strftime(\"%d/%m/%Y, %H:%M:%S\"),\n",
    "                                            dereg_value_retrieval(listing_url)))\n",
    "    print(f\"OMV: {omv_retrieval(listing_url)}\\n\")\n",
    "    print(f\"ARF: {arf_retrieval(listing_url)}\\n\")\n",
    "    print(f\"COE as of Today: {coe_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Days of COE Left: {days_of_coe_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Engine Capacity (CC):{ engine_capacity_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Curb Weight (kg): {curb_weight_retrieval(listing_url)}\\n\")\n",
    "    print(f\"# Of Owners: {number_of_owners_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Vehicle Type:{type_of_vehicle_retrieval(listing_url)}\\n\")\n",
    "                                        \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_scraper2(listing_url_list):\n",
    "    \"\"\"Accepts a list of individual car listing urls and returns variables of importance for linear regression analysis.\n",
    "    ---\n",
    "    Input: List of urls\n",
    "    Output: Variables\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    # Retrieval functions\n",
    "    df.loc[i, 'LISTING_URL'] = listing_url\n",
    "    df.loc[i, 'BRAND'] = brand_retrieval(listing_url)\n",
    "    df.loc[i, 'PRICE'] = price_retrieval(listing_url)\n",
    "    try:\n",
    "        df.loc[i, 'DEPRE_VALUE_PER_YEAR'] = depreciation_value_per_year_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'DEPRE_VALUE_PER_YEAR'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'REG_DATE'] = registered_date_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'REG_DATE'] = np.nan\n",
    "    \n",
    "    try:\n",
    "        df.loc[i, 'MILEAGE_KM'] = mileage_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'MILEAGE_KM'] = np.nan\n",
    "    \n",
    "    \n",
    "        df.loc[i, 'MANUFACTURED_YEAR'] = manufactured_year_retrieval(listing_url)\n",
    "        df.loc[i, 'ROAD_TAX_PER_YEAR'] = road_tax_retrieval(listing_url)\n",
    "        df.loc[i, 'TRANSMISSION'] = transmission_retrieval(listing_url)\n",
    "        df.loc[i, 'DEREG_VALUE_FROM_SCRAPE_DATE'] = dereg_value_retrieval(listing_url)\n",
    "        df.loc[i, 'SCRAPE_DATE'] = datetime.now().strftime(\"%d/%m/%Y\")\n",
    "        df.loc[i, 'OMV'] = omv_retrieval(listing_url)\n",
    "        df.loc[i, 'ARF'] = arf_retrieval(listing_url)\n",
    "        df.loc[i, 'COE_FROM_SCRAPE_DATE'] = coe_retrieval(listing_url)\n",
    "        df.loc[i, 'DAYS_OF_COE_LEFT'] = days_of_coe_retrieval(listing_url)\n",
    "        df.loc[i, 'ENGINE_CAPACITY_CC'] = engine_capacity_retrieval(listing_url)\n",
    "        df.loc[i, 'CURB_WEIGHT_KG'] = curb_weight_retrieval(listing_url)\n",
    "        try:\n",
    "        df.loc[i, 'NO_OF_OWNERS'] = number_of_owners_retrieval(listing_url)\n",
    "    except ValueError:\n",
    "        df.loc[i, 'NO_OF_OWNERS'] = np.nan\n",
    "    df.loc[i, 'VEHICLE_TYPE'] = type_of_vehicle_retrieval(listing_url)\n",
    "                                        \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_scraper3(listing_url_list):\n",
    "    \"\"\"Accepts a list of individual car listing urls and returns variables of importance for linear regression analysis.\n",
    "    ---\n",
    "    Input: List of urls\n",
    "    Output: Variables\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    # Retrieval functions\n",
    "    df.loc[i, 'LISTING_URL'] = listing_url\n",
    "    df.loc[i, 'BRAND'] = brand_retrieval(listing_url)\n",
    "    df.loc[i, 'PRICE'] = price_retrieval(listing_url)\n",
    "    try:\n",
    "        df.loc[i, 'DEPRE_VALUE_PER_YEAR'] = depreciation_value_per_year_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'DEPRE_VALUE_PER_YEAR'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'REG_DATE'] = registered_date_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'REG_DATE'] = np.nan\n",
    "    \n",
    "    try:\n",
    "        df.loc[i, 'MILEAGE_KM'] = mileage_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'MILEAGE_KM'] = np.nan\n",
    "    \n",
    "    try:\n",
    "        df.loc[i, 'MANUFACTURED_YEAR'] = manufactured_year_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'MANUFACTURED_YEAR'] = np.nan\n",
    "    \n",
    "    try:\n",
    "        df.loc[i, 'ROAD_TAX_PER_YEAR'] = road_tax_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'ROAD_TAX_PER_YEAR'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'TRANSMISSION'] = transmission_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'TRANSMISSION'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'DEREG_VALUE_FROM_SCRAPE_DATE'] = dereg_value_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'DEREG_VALUE_FROM_SCRAPE_DATE'] = np.nan\n",
    "        \n",
    "    df.loc[i, 'SCRAPE_DATE'] = datetime.now().strftime(\"%d/%m/%Y\")\n",
    "    \n",
    "    try:\n",
    "        df.loc[i, 'OMV'] = omv_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'OMV'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'ARF'] = arf_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'ARF'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'COE_FROM_SCRAPE_DATE'] = coe_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'COE_FROM_SCRAPE_DATE'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'DAYS_OF_COE_LEFT'] = days_of_coe_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'DAYS_OF_COE_LEFT'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'ENGINE_CAPACITY_CC'] = engine_capacity_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'ENGINE_CAPACITY_CC'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'CURB_WEIGHT_KG'] = curb_weight_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'CURB_WEIGHT_KG'] = np.nan\n",
    "    try:\n",
    "        df.loc[i, 'NO_OF_OWNERS'] = number_of_owners_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'NO_OF_OWNERS'] = np.nan\n",
    "    try:\n",
    "        df.loc[i, 'VEHICLE_TYPE'] = type_of_vehicle_retrieval(listing_url)\n",
    "    except:\n",
    "                                        \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty DataFrame for attributes of interest\n",
    "df = pd.DataFrame(columns=['LISTING_URL', 'BRAND', 'PRICE', 'DEPRE_VALUE_PER_YEAR',\n",
    "       'REG_DATE', 'MILEAGE_KM', 'MANUFACTURED_YEAR',\n",
    "       'ROAD_TAX_PER_YEAR','TRANSMISSION', 'DEREG_VALUE_FROM_SCRAPE_DATE',\n",
    "       'SCRAPE_DATE', 'OMV', 'ARF', 'COE_FROM_SCRAPE_DATE',\n",
    "       'DAYS_OF_COE_LEFT', 'ENGINE_CAPACITY_CC', 'CURB_WEIGHT_KG',\n",
    "       'NO_OF_OWNERS', 'VEHICLE_TYPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 19 columns):\n",
      "LISTING_URL                     0 non-null object\n",
      "BRAND                           0 non-null object\n",
      "PRICE                           0 non-null object\n",
      "DEPRE_VALUE_PER_YEAR            0 non-null object\n",
      "REG_DATE                        0 non-null object\n",
      "MILEAGE_KM                      0 non-null object\n",
      "MANUFACTURED_YEAR               0 non-null object\n",
      "ROAD_TAX_PER_YEAR               0 non-null object\n",
      "TRANSMISSION                    0 non-null object\n",
      "DEREG_VALUE_FROM_SCRAPE_DATE    0 non-null object\n",
      "SCRAPE_DATE                     0 non-null object\n",
      "OMV                             0 non-null object\n",
      "ARF                             0 non-null object\n",
      "COE_FROM_SCRAPE_DATE            0 non-null object\n",
      "DAYS_OF_COE_LEFT                0 non-null object\n",
      "ENGINE_CAPACITY_CC              0 non-null object\n",
      "CURB_WEIGHT_KG                  0 non-null object\n",
      "NO_OF_OWNERS                    0 non-null object\n",
      "VEHICLE_TYPE                    0 non-null object\n",
      "dtypes: object(19)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-5ceb0bfcf173>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlisting_url\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlisting_urls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mattribute_scraper2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlisting_urls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-2139729bc2db>\u001b[0m in \u001b[0;36mattribute_scraper2\u001b[1;34m(listing_url_list)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'BRAND'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrand_retrieval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlisting_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PRICE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprice_retrieval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlisting_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DEPRE_VALUE_PER_YEAR'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdepreciation_value_per_year_retrieval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlisting_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'REG_DATE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregistered_date_retrieval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlisting_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MILEAGE_KM'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmileage_retrieval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlisting_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-af44b01b0da0>\u001b[0m in \u001b[0;36mdepreciation_value_per_year_retrieval\u001b[1;34m(listing_url)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mparsed_listing_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mdata_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsed_listing_url\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindNextSibling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'$'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/yr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mdepreciation_value_per_year\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdepreciation_value_per_year_error_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for listing_url in listing_urls:\n",
    "    attribute_scraper2(listing_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.now().strftime(\"%d/%m/%Y, %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attribute_scraper('https://www.sgcarmart.com/used_cars/info.php?ID=781368&DL=1034')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
