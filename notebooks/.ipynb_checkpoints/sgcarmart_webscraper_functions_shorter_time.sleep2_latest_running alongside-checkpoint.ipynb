{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_url = \"https://www.sgcarmart.com/used_cars/info.php?ID=862831&DL=3417\"\n",
    "response2 = requests.get(listing_url)\n",
    "response2.status_code\n",
    "page2 = response2.text\n",
    "main_page2 = BeautifulSoup(page2, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing URL Grabber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title/Brand Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Honda\n",
      "Subaru\n"
     ]
    }
   ],
   "source": [
    "# Define a function to retrieve car brand name given a listing url\n",
    "\n",
    "def brand_retrieval(parsed_url):\n",
    "    brand_name = parsed_url.find(class_='link_redbanner').text.split()[0]\n",
    "    return brand_name\n",
    "\n",
    "\n",
    "\n",
    "listing_url = 'https://www.sgcarmart.com/used_cars/info.php?ID=863352&DL=1000'\n",
    "listing_url2 = 'https://www.sgcarmart.com/used_cars/info.php?ID=863354&DL=1281'\n",
    "response = requests.get(listing_url)\n",
    "response2 = requests.get(listing_url2)\n",
    "parsed_listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "parsed_listing_url2 = BeautifulSoup(response2.text, 'lxml')\n",
    "print(brand_retrieval(parsed_listing_url))\n",
    "print(brand_retrieval(parsed_listing_url2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52888\n",
      "10500\n"
     ]
    }
   ],
   "source": [
    "def price_retrieval(parsed_listing_url):\n",
    "    \n",
    "    data_value = parsed_listing_url.find_all(class_='font_red')[0].text.strip()\n",
    "    data_value = data_value.split('$')\n",
    "    price = price_error_handling(data_value)\n",
    "    return price\n",
    "\n",
    "\n",
    "def price_error_handling(data_value):\n",
    "    # Try-Exception error handling\n",
    "    \n",
    "    try:   # First try to deal with values higher than 1000\n",
    "        price = data_value[1]  # will fail on IndexError if retrieves ['na'] scenario\n",
    "        price = int(price.split(',')[0] + price.split(',')[1]) # Will fail on IndexError if tries to split '900' with a ',' in ['',900]\n",
    "        \n",
    "    except IndexError:  # Dealing with ['na'] and ['', 900'] scenarios\n",
    "        try: \n",
    "            price = int(data_value[1]) # Will fail on IndexError if ['na'] scenario\n",
    "        except IndexError:  # Deals with ['na'] scenarios\n",
    "            price = np.nan  # Stores NA values as nan\n",
    "    \n",
    "    return price\n",
    "\n",
    "\n",
    "listing_url = 'https://www.sgcarmart.com/used_cars/info.php?ID=863352&DL=1000'\n",
    "listing_url2 = 'https://www.sgcarmart.com/used_cars/info.php?ID=863354&DL=1281'\n",
    "response = requests.get(listing_url)\n",
    "response2 = requests.get(listing_url2)\n",
    "parsed_listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "parsed_listing_url2 = BeautifulSoup(response2.text, 'lxml')\n",
    "print(price_retrieval(parsed_listing_url))\n",
    "print(price_retrieval(parsed_listing_url2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depreciation Value Per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5780\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define a function that retrieves depreciation value per year given a listing url\n",
    "def depreciation_value_per_year_error_handler(data_value):\n",
    "    if len(data_value) < 2:\n",
    "        data_value = np.nan\n",
    "\n",
    "    else: \n",
    "        data_value = data_value[1].split('/yr')\n",
    "        try:                 \n",
    "            desired_value = int(data_value[0].split(',')[0] +\\\n",
    "                                data_value[0].split(',')[1]) # Will fail on IndexError if tries to split '900' with a ',' in ['900','']\n",
    "        except IndexError: \n",
    "            desired_value = int(data_value[0])\n",
    "        \n",
    "        return desired_value\n",
    "    \n",
    "def depreciation_value_per_year_retrieval(parsed_listing_url):\n",
    "    data_value = parsed_listing_url.find_all(class_=\"label\")[1].findNextSibling().text.strip().split('$')\n",
    "    depreciation_value_per_year = depreciation_value_per_year_error_handler(data_value)\n",
    "    return depreciation_value_per_year\n",
    "\n",
    "\n",
    "\n",
    "listing_url = 'https://www.sgcarmart.com/used_cars/info.php?ID=863352&DL=1000'\n",
    "response = requests.get(listing_url)\n",
    "parsed_listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "listing_url2 = 'https://www.sgcarmart.com/used_cars/info.php?ID=863354&DL=1281'\n",
    "response2 = requests.get(listing_url2)\n",
    "parsed_listing_url2 = BeautifulSoup(response2.text, 'lxml')\n",
    "\n",
    "print(depreciation_value_per_year_retrieval(parsed_listing_url))\n",
    "print(depreciation_value_per_year_retrieval(parsed_listing_url2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road Tax/Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814\n",
      "684\n"
     ]
    }
   ],
   "source": [
    "# Define a function to retrieve road tax /yr given a listing url\n",
    "def road_tax_retrieval(parsed_listing_url):\n",
    "    string_data = parsed_listing_url.find_all(class_='row_info')[1].text.strip()\n",
    "    road_tax_yearly = road_tax_error_handler(string_data)\n",
    "    \n",
    "    return road_tax_yearly\n",
    "    \n",
    "\n",
    "def road_tax_error_handler(string_data):\n",
    "    if '/yr' in string_data: # Only takes in scenarios that are not NA\n",
    "        try:\n",
    "            # Removes '$\" character and splits string_data into a list of ['', 1,000] or ['', 900]\n",
    "            road_tax_per_year = \\\n",
    "            string_data.replace('/yr','').strip().split('$') \n",
    "\n",
    "            # Accesses the second item in the list\n",
    "            road_tax_per_year = road_tax_per_year[1] \n",
    "\n",
    "\n",
    "            road_tax_per_year = int(road_tax_per_year.split(',')[0] +\\\n",
    "                                    road_tax_per_year.split(',')[1])  # Will fail on IndexError if value is above 1000\n",
    "\n",
    "        except IndexError: # Handles values that are below 1000. (i.e. ['',900])\n",
    "            road_tax_pear_year = int(road_tax_per_year[1])\n",
    "\n",
    "    else: # Deals with 'NA' scenario\n",
    "        road_tax_per_year = np.nan\n",
    "    \n",
    "    return road_tax_per_year\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "listing_url = 'https://www.sgcarmart.com/used_cars/info.php?ID=863352&DL=1000'\n",
    "response = requests.get(listing_url)\n",
    "parsed_listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "listing_url2 = 'https://www.sgcarmart.com/used_cars/info.php?ID=863354&DL=1281'\n",
    "response2 = requests.get(listing_url2)\n",
    "parsed_listing_url2 = BeautifulSoup(response2.text, 'lxml')\n",
    "    \n",
    "    \n",
    "print(road_tax_retrieval(parsed_listing_url))\n",
    "print(road_tax_retrieval(parsed_listing_url2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registered Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15-Dec-2008\n",
      "25-Feb-2010\n"
     ]
    }
   ],
   "source": [
    "# Define function to retrieve Registered date given a parsed listing url\n",
    "\n",
    "# url to parse from \"https://www.sgcarmart.com/used_cars/info.php?ID=862816&DL=2397\"\n",
    "# listing_url = \"https://www.sgcarmart.com/used_cars/info.php?ID=862831&DL=3417\"\n",
    "# response2 = requests.get(listing_url)\n",
    "# page2 = response2.text\n",
    "# parsed_listing_url = BeautifulSoup(page2, 'lxml')\n",
    "\n",
    "\n",
    "def registered_date_retrieval(parsed_listing_url):\n",
    "    reg_date = parsed_listing_url.find_all(class_='row_bg')[1].find_all('td')[3].text.split()[0].split('(')[0]\n",
    "    return reg_date\n",
    "\n",
    "\n",
    "\n",
    "listing_url = 'https://www.sgcarmart.com/used_cars/info.php?ID=863352&DL=1000'\n",
    "response = requests.get(listing_url)\n",
    "parsed_listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "listing_url2 = 'https://www.sgcarmart.com/used_cars/info.php?ID=863354&DL=1281'\n",
    "response2 = requests.get(listing_url2)\n",
    "parsed_listing_url2 = BeautifulSoup(response2.text, 'lxml')\n",
    "\n",
    "\n",
    "print(registered_date_retrieval(parsed_listing_url))\n",
    "print(registered_date_retrieval(parsed_listing_url2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Days of COE Left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3316\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "# Define a function to retrieve days of COE left in terms of days:\n",
    "\n",
    "# Retrieve into usable format for link\n",
    "def days_of_coe_retrieval(parsed_listing_url):\n",
    "    \"\"\"Takes in a listing page (individual cars) and retrieve the days of COE left\n",
    "    ---\n",
    "    Input: str\n",
    "    Output: Days of COE left in integer form\n",
    "    \"\"\"\n",
    "    days_of_coe_left_yy_mm_dd_format_for_cleaner_function=\\\n",
    "    parsed_listing_url.find_all(class_='row_bg')[1].find_all('td')[3].text.split('(')[1].split('COE')[0].strip()\n",
    "    \n",
    "    return yr_mm_dd_cleaner(days_of_coe_left_yy_mm_dd_format_for_cleaner_function)\n",
    "\n",
    "\n",
    "# Define a function to calculate days of COE left\n",
    "def yr_mm_dd_cleaner(str1):\n",
    "    \"\"\"Accepts a string that may or may include the elements yr mths days and \n",
    "    converts the whole string into number of days.\n",
    "    ----\n",
    "    Input: single string\n",
    "    output: number of days in integer form\n",
    "    ----\n",
    "    Example string inputs:\n",
    "    - 4yrs 2mths 23days\n",
    "    - 5yrs\n",
    "    - 2 mths 23 days\n",
    "    - 50 days\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert days_of_coe_left_yy_mm_dd to days    \n",
    "    year_index = str1.find('yr')\n",
    "    if year_index == -1:\n",
    "        year = 0\n",
    "    else:\n",
    "        year = int(str1[year_index-1])\n",
    "\n",
    "        \n",
    "    mth_index = str1.find('mth')\n",
    "    if mth_index == -1:\n",
    "        mth = 0\n",
    "    else:\n",
    "        mth = int(str1[mth_index-1])\n",
    "\n",
    "        \n",
    "    day_index = str1.find('day')\n",
    "    if day_index == -1:\n",
    "        day = 0\n",
    "    else:\n",
    "        day = int(str1[day_index-1])\n",
    "       \n",
    "    days_of_coe_left = (year * 365) + (mth * 30) + day \n",
    "    return days_of_coe_left\n",
    "\n",
    "\n",
    "\n",
    "listing_url = 'https://www.sgcarmart.com/used_cars/info.php?ID=863352&DL=1000'\n",
    "response = requests.get(listing_url)\n",
    "parsed_listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "listing_url2 = 'https://www.sgcarmart.com/used_cars/info.php?ID=863354&DL=1281'\n",
    "response2 = requests.get(listing_url2)\n",
    "parsed_listing_url2 = BeautifulSoup(response2.text, 'lxml')\n",
    "\n",
    "\n",
    "print(days_of_coe_retrieval(parsed_listing_url))\n",
    "print(days_of_coe_retrieval(parsed_listing_url2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mileage in km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000\n",
      "92000\n"
     ]
    }
   ],
   "source": [
    "# Write a function to retrieve the mileage in km from a listjng url\n",
    "\n",
    "def mileage_error_handler(data_value):\n",
    "    if len(data_value) < 2:  # Deals with ['na'] scenarios\n",
    "        mileage_km = np.nan  # Stores NA values as nan\n",
    "\n",
    "    else:  \n",
    "        try:                 \n",
    "            mileage_km = int(data_value[0].strip().split(',')[0] + data_value[0].strip().split(',')[1])\n",
    "        except IndexError: # Will fail on IndexError if tries to split '900' with a ',' in ['',900]\n",
    "            mileage_km = int(data_value[0].strip())\n",
    "    \n",
    "    return mileage_km\n",
    "\n",
    "def mileage_retrieval(parsed_listing_url):\n",
    "        \n",
    "    data_value = parsed_listing_url.find_all(class_='row_info')[0].text.strip()\n",
    "    data_value = data_value.split('km')\n",
    "    mileage_km = mileage_error_handler(data_value)\n",
    "    \n",
    "    return mileage_km\n",
    "\n",
    "listing_url = 'https://www.sgcarmart.com/used_cars/info.php?ID=863352&DL=1000'\n",
    "response = requests.get(listing_url)\n",
    "parsed_listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "listing_url2 = 'https://www.sgcarmart.com/used_cars/info.php?ID=863354&DL=1281'\n",
    "response2 = requests.get(listing_url2)\n",
    "parsed_listing_url2 = BeautifulSoup(response2.text, 'lxml')\n",
    "\n",
    "\n",
    "print(mileage_retrieval(parsed_listing_url)) \n",
    "print(mileage_retrieval(parsed_listing_url2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manufactured Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008\n",
      "2009\n"
     ]
    }
   ],
   "source": [
    "# Define a function that returns the manufactured date using a parsed html\n",
    "def manufactured_year_retrieval(parsed_listing_url):\n",
    "    manufactured_year = parsed_listing_url.find_all(class_='row_info')[6].text\n",
    "    return manufactured_year\n",
    "\n",
    "\n",
    "\n",
    "listing_url = 'https://www.sgcarmart.com/used_cars/info.php?ID=863352&DL=1000'\n",
    "response = requests.get(listing_url)\n",
    "parsed_listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "listing_url2 = 'https://www.sgcarmart.com/used_cars/info.php?ID=863354&DL=1281'\n",
    "response2 = requests.get(listing_url2)\n",
    "parsed_listing_url2 = BeautifulSoup(response2.text, 'lxml')\n",
    "\n",
    "\n",
    "print(manufactured_year_retrieval(parsed_listing_url))\n",
    "print(manufactured_year_retrieval(parsed_listing_url2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto\n",
      "Manual\n"
     ]
    }
   ],
   "source": [
    "# Define a function that returns the transmission based on a parsed listing url\n",
    "\n",
    "def transmission_retrieval(parsed_listing_url):\n",
    "    transmission = parsed_listing_url.find_all(class_='row_info')[7].text\n",
    "    return transmission\n",
    "\n",
    "\n",
    "listing_url = 'https://www.sgcarmart.com/used_cars/info.php?ID=863352&DL=1000'\n",
    "response = requests.get(listing_url)\n",
    "parsed_listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "listing_url2 = 'https://www.sgcarmart.com/used_cars/info.php?ID=863354&DL=1281'\n",
    "response2 = requests.get(listing_url2)\n",
    "parsed_listing_url2 = BeautifulSoup(response2.text, 'lxml')\n",
    "\n",
    "\n",
    "print(transmission_retrieval(parsed_listing_url))\n",
    "print(transmission_retrieval(parsed_listing_url2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dereg Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25229\n",
      "7978\n"
     ]
    }
   ],
   "source": [
    "# Write a function to retrieve dereg value from a parsed url\n",
    "\n",
    "def dereg_value_retrieval(parsed_listing_url):\n",
    "    # Splits into ['NA'], or ['$11,026', 'as', 'of', 'today', '(change)'] or ['$900', 'as', 'of', 'today', '(change)']\n",
    "    data_value = parsed_listing_url.find_all(class_='row_info')[2].text.strip().split() \n",
    "    \n",
    "    dereg_value_from_scrape_date = dereg_value_error_handler(data_value)\n",
    "    return dereg_value_from_scrape_date\n",
    "    \n",
    "\n",
    "def dereg_value_error_handler(data_value):\n",
    "    if len(data_value) < 2:  # Deals with ['NA'] scenario\n",
    "        dereg_value_from_scrape_date = np.nan\n",
    "\n",
    "    else: \n",
    "        data_value = data_value[0].split('$')[1] # Puts input into '11,026' or '900' format\n",
    "        try:                 \n",
    "            dereg_value_from_scrape_date = \\\n",
    "            int(data_value.split(',')[0] +\\\n",
    "                data_value.split(',')[1]) # Will fail on IndexError if tries to split '900' with a ',' in ['',900]\n",
    "        except IndexError: \n",
    "            dereg_value_from_scrape_date = int(data_value.strip())\n",
    "\n",
    "        return dereg_value_from_scrape_date\n",
    " \n",
    "\n",
    "listing_url = 'https://www.sgcarmart.com/used_cars/info.php?ID=863352&DL=1000'\n",
    "response = requests.get(listing_url)\n",
    "parsed_listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "listing_url2 = 'https://www.sgcarmart.com/used_cars/info.php?ID=863354&DL=1281'\n",
    "response2 = requests.get(listing_url2)\n",
    "parsed_listing_url2 = BeautifulSoup(response2.text, 'lxml')\n",
    "\n",
    "print(dereg_value_retrieval(parsed_listing_url))\n",
    "print(dereg_value_retrieval(parsed_listing_url2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OMV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20407\n",
      "14597\n"
     ]
    }
   ],
   "source": [
    "# Define a function that retrieves omv based on a parsed listing url\n",
    "def omv_error_handler(data_value):\n",
    "    if len(data_value) < 2:  # deals iwth ['NA'] input\n",
    "        omv = np.nan\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            omv = int(data_value[1].split(',')[0] +\\\n",
    "                      data_value[1].split(',')[1])  # Will fail on index error if try to split 900\n",
    "        except IndexError:\n",
    "            omv = int(data_value[1])\n",
    "    return omv\n",
    "\n",
    "\n",
    "def omv_retrieval(parsed_listing_url):    \n",
    "    data_value = parsed_listing_url.find_all(class_='row_info')[8].text.split('$') \n",
    "    # Splits data into ['', '21,967'], ['','900'] or ['NA'] format for input into error function\n",
    "    \n",
    "    omv = omv_error_handler(data_value)\n",
    "    return omv     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "listing_url = 'https://www.sgcarmart.com/used_cars/info.php?ID=863352&DL=1000'\n",
    "response = requests.get(listing_url)\n",
    "parsed_listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "listing_url2 = 'https://www.sgcarmart.com/used_cars/info.php?ID=863354&DL=1281'\n",
    "response2 = requests.get(listing_url2)\n",
    "parsed_listing_url2 = BeautifulSoup(response2.text, 'lxml')\n",
    "\n",
    "\n",
    "print(omv_retrieval(parsed_listing_url))\n",
    "print(omv_retrieval(parsed_listing_url2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20407\n",
      "14597\n"
     ]
    }
   ],
   "source": [
    "# Write a function that retrieves ARF based on a parsed listing url\n",
    "def error_handler(data_value):\n",
    "    if len(data_value) < 2:  # deals iwth ['NA'] input\n",
    "        desired_value = np.nan\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            desired_value = int(data_value[1].split(',')[0] +\\\n",
    "                                data_value[1].split(',')[1])   # Will fail on index error if try to split 900\n",
    "        except IndexError:\n",
    "            desired_value = int(data_value[1])\n",
    "    return desired_value\n",
    "\n",
    "\n",
    "def arf_retrieval(parsed_listing_url):\n",
    "    data_value = parsed_listing_url.find_all(class_='row_info')[9].text.split('$')\n",
    "    arf = error_handler(data_value)\n",
    "    return arf\n",
    "\n",
    "\n",
    "\n",
    "listing_url = 'https://www.sgcarmart.com/used_cars/info.php?ID=863352&DL=1000'\n",
    "response = requests.get(listing_url)\n",
    "parsed_listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "listing_url2 = 'https://www.sgcarmart.com/used_cars/info.php?ID=863354&DL=1281'\n",
    "response2 = requests.get(listing_url2)\n",
    "parsed_listing_url2 = BeautifulSoup(response2.text, 'lxml')\n",
    "\n",
    "\n",
    "\n",
    "print(arf_retrieval(parsed_listing_url))\n",
    "print(arf_retrieval(parsed_listing_url2))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COE Price as of Today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27571\n",
      "19989\n"
     ]
    }
   ],
   "source": [
    "# Write a function to retrieve COE as of today from a parsed listing url\n",
    "def coe_error_handler(data_value):\n",
    "    if len(data_value) < 2:  # deals iwth ['NA'] input\n",
    "        coe_from_scrape_date = np.nan\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            coe_from_scrape_date = int(data_value[1].split(',')[0] +\\\n",
    "                                       data_value[1].split(',')[1])  # Will fail on index error if try to split 900\n",
    "        except IndexError:\n",
    "            coe_from_scrape_date = int(data_value[1])\n",
    "    return coe_from_scrape_date\n",
    "\n",
    "\n",
    "def coe_retrieval(parsed_listing_url):\n",
    "    data_value = parsed_listing_url.find_all(class_='row_info')[3].text.split('$')\n",
    "    coe_from_scrape_date = coe_error_handler(data_value)\n",
    "    return coe_from_scrape_date\n",
    "  \n",
    "    \n",
    "\n",
    "listing_url = 'https://www.sgcarmart.com/used_cars/info.php?ID=863352&DL=1000'\n",
    "response = requests.get(listing_url)\n",
    "parsed_listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "listing_url2 = 'https://www.sgcarmart.com/used_cars/info.php?ID=863354&DL=1281'\n",
    "response2 = requests.get(listing_url2)\n",
    "parsed_listing_url2 = BeautifulSoup(response2.text, 'lxml')\n",
    "\n",
    "    \n",
    "print(coe_retrieval(parsed_listing_url))\n",
    "print(coe_retrieval(parsed_listing_url2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engine Capacity (CC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1595\n",
      "1498\n"
     ]
    }
   ],
   "source": [
    "def engine_capacity_error_handler(data_value):\n",
    "    if len(data_value) < 2:  # deals iwth ['NA'] input\n",
    "        desired_value = np.nan\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            desired_value = int(data_value[0].split(',')[0] +\\\n",
    "                                       data_value[0].split(',')[1])  # Will fail on index error if try to split 900\n",
    "        except IndexError:\n",
    "            desired_value = int(data_value[0])\n",
    "    return desired_value\n",
    "\n",
    "\n",
    "def engine_capacity_retrieval(parsed_listing_url):\n",
    "    data_value = parsed_listing_url.find_all(class_='row_info')[4].text.strip().split('cc')\n",
    "    engine_capacity = engine_capacity_error_handler(data_value)\n",
    "    return engine_capacity\n",
    "\n",
    "\n",
    "listing_url = 'https://www.sgcarmart.com/used_cars/info.php?ID=863352&DL=1000'\n",
    "response = requests.get(listing_url)\n",
    "parsed_listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "listing_url2 = 'https://www.sgcarmart.com/used_cars/info.php?ID=863354&DL=1281'\n",
    "response2 = requests.get(listing_url2)\n",
    "parsed_listing_url2 = BeautifulSoup(response2.text, 'lxml')\n",
    "\n",
    "\n",
    "print(engine_capacity_retrieval(parsed_listing_url))\n",
    "print(engine_capacity_retrieval(parsed_listing_url2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power (kW) Something to consider for the future. No time already\n",
    "refer to car_webscraper if you want to work on it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curb Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1220\n",
      "1310\n"
     ]
    }
   ],
   "source": [
    "def curb_weight_error_handler(data_value):\n",
    "    if len(data_value) < 2:  # deals iwth ['NA'] input\n",
    "        desired_value = np.nan\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            desired_value = int(data_value[0].split(',')[0] +\\\n",
    "                                       data_value[0].split(',')[1])  # Will fail on index error if try to split 900\n",
    "        except IndexError:\n",
    "            desired_value = int(data_value[0])\n",
    "    return desired_value\n",
    "\n",
    "\n",
    "def curb_weight_retrieval(parsed_listing_url):\n",
    "    data_value = parsed_listing_url.find_all(class_='row_info')[5].text.split()\n",
    "    curb_weight = curb_weight_error_handler(data_value)\n",
    "    return curb_weight\n",
    "\n",
    "\n",
    "listing_url = 'https://www.sgcarmart.com/used_cars/info.php?ID=863352&DL=1000'\n",
    "response = requests.get(listing_url)\n",
    "parsed_listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "listing_url2 = 'https://www.sgcarmart.com/used_cars/info.php?ID=863354&DL=1281'\n",
    "response2 = requests.get(listing_url2)\n",
    "parsed_listing_url2 = BeautifulSoup(response2.text, 'lxml')\n",
    "\n",
    "\n",
    "print(curb_weight_retrieval(parsed_listing_url))\n",
    "print(curb_weight_retrieval(parsed_listing_url2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No. Of Owners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Define a function to retrieve the no of owners from a parsed listing url\n",
    "def number_of_owners_retrieval(parsed_listing_url):\n",
    "    no_of_owners = int(parsed_listing_url.find_all(class_='row_info')[-1].text)\n",
    "    return no_of_owners\n",
    "\n",
    "\n",
    "listing_url = 'https://www.sgcarmart.com/used_cars/info.php?ID=863352&DL=1000'\n",
    "response = requests.get(listing_url)\n",
    "parsed_listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "listing_url2 = 'https://www.sgcarmart.com/used_cars/info.php?ID=863354&DL=1281'\n",
    "response2 = requests.get(listing_url2)\n",
    "parsed_listing_url2 = BeautifulSoup(response2.text, 'lxml')\n",
    "\n",
    "print(number_of_owners_retrieval(parsed_listing_url))\n",
    "print(number_of_owners_retrieval(parsed_listing_url2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type of Vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mid-Sized Sedan\n",
      "Mid-Sized Sedan\n"
     ]
    }
   ],
   "source": [
    "# Define a function that returns the type of vehicle given a parsed listing url\n",
    "\n",
    "def type_of_vehicle_retrieval(parsed_listing_url):\n",
    "    type_of_vehicle = parsed_listing_url.find(class_='row_bg1').find_all('a')[0].text \n",
    "    return type_of_vehicle\n",
    "\n",
    "listing_url = 'https://www.sgcarmart.com/used_cars/info.php?ID=863352&DL=1000'\n",
    "response = requests.get(listing_url)\n",
    "parsed_listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "listing_url2 = 'https://www.sgcarmart.com/used_cars/info.php?ID=863354&DL=1281'\n",
    "response2 = requests.get(listing_url2)\n",
    "parsed_listing_url2 = BeautifulSoup(response2.text, 'lxml')\n",
    "\n",
    "print(type_of_vehicle_retrieval(parsed_listing_url))\n",
    "print(type_of_vehicle_retrieval(parsed_listing_url2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WebScraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of main pages to iterate through\n",
    "main_page_listing_list = []\n",
    "for idx, link in enumerate(range(30)):\n",
    "    url = \"https://www.sgcarmart.com/used_cars/listing.php?BRSR=\" + str(idx * 100) + \"&RPG=100&AVL=2&VEH=2\"\n",
    "    main_page_listing_list.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.sgcarmart.com/used_cars/listing.php?BRSR=0&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=100&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=200&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=300&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=400&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=500&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=600&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=700&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=800&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=900&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1000&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1100&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1200&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1300&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1400&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1500&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1600&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1700&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1800&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1900&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2000&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2100&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2200&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2300&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2400&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2500&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2600&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2700&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2800&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2900&RPG=100&AVL=2&VEH=2'] \n",
      " \n",
      " 30\n"
     ]
    }
   ],
   "source": [
    "print(main_page_listing_list,'\\n','\\n', len(main_page_listing_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving individual listing urls from main pages of 100 listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base url, or you can think of this as the individual car listing prefix\n",
    "base_url = 'https://www.sgcarmart.com/used_cars/'\n",
    "listing_urls = []\n",
    "\n",
    "# Acquiring indvidual car listings    \n",
    "for main_link in main_page_listing_list:\n",
    "   \n",
    "    # Make a request to the website and get the object\n",
    "    content = requests.get(main_link)\n",
    "\n",
    "    # Parse the HTML text\n",
    "    soup = BeautifulSoup(content.text, 'lxml')\n",
    "\n",
    "    # Find every single URL in the webpage , refer to this post: # https://stackoverflow.com/questions/46490626/getting-all-links-from-a-page-beautiful-soup\n",
    "    # This returns a list of every tag that contains a link in one main link (each element in main page listing)\n",
    "    links = soup.find_all('a')\n",
    "    \n",
    "    # Create a list for storing all the individual listing urls\n",
    "    \n",
    "    for link in links:\n",
    "        # Get link in <a href>\n",
    "        suffix = link.get('href')\n",
    "\n",
    "        # Check if 'ID=' and 'DL=' exist in the string\n",
    "        if ('ID=' in suffix) and ('DL=' in suffix):\n",
    "\n",
    "            # Concatenate the two strings if they do\n",
    "            listing_url = base_url + suffix\n",
    "            \n",
    "            # Append result to the list\n",
    "            listing_urls.append(listing_url)\n",
    "            \n",
    "#     Removing duplicates\n",
    "    set_listing_urls = set(listing_urls)\n",
    "    listing_urls = list(set_listing_urls)\n",
    "    \n",
    "    # Prevent oneself from getting blocked from the website\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(listing_urls))\n",
    "print(len(set(listing_urls)))\n",
    "print(len(list(set(listing_urls))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(listing_urls[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty DataFrame for attributes of interest\n",
    "df = pd.DataFrame(columns=['LISTING_URL', 'BRAND', 'PRICE', 'DEPRE_VALUE_PER_YEAR',\n",
    "       'REG_DATE', 'MILEAGE_KM', 'MANUFACTURED_YEAR',\n",
    "       'ROAD_TAX_PER_YEAR','TRANSMISSION', 'DEREG_VALUE_FROM_SCRAPE_DATE',\n",
    "       'SCRAPE_DATE', 'OMV', 'ARF', 'COE_FROM_SCRAPE_DATE',\n",
    "       'DAYS_OF_COE_LEFT', 'ENGINE_CAPACITY_CC', 'CURB_WEIGHT_KG',\n",
    "       'NO_OF_OWNERS', 'VEHICLE_TYPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'sgcarmart_used_cars_prices2'\n",
    "i = 0 # Indexing rows in the DF\n",
    "\n",
    "for listingurl in listing_urls:\n",
    "    response = requests.get(listingurl)\n",
    "    listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    # Retrieval functions to pull data from the Individual Listings after they have been parsed\n",
    "    df.loc[i, 'LISTING_URL'] = listingurl\n",
    "    df.loc[i, 'BRAND'] = brand_retrieval(listing_url)\n",
    "    df.loc[i, 'PRICE'] = price_retrieval(listing_url)\n",
    "    try:\n",
    "        df.loc[i, 'DEPRE_VALUE_PER_YEAR'] = depreciation_value_per_year_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'DEPRE_VALUE_PER_YEAR'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'REG_DATE'] = registered_date_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'REG_DATE'] = np.nan\n",
    "    \n",
    "    try:\n",
    "        df.loc[i, 'MILEAGE_KM'] = mileage_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'MILEAGE_KM'] = np.nan\n",
    "\n",
    "    try:\n",
    "        df.loc[i, 'MANUFACTURED_YEAR'] = manufactured_year_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'MANUFACTURED_YEAR'] = np.nan\n",
    "    \n",
    "    try:\n",
    "        df.loc[i, 'ROAD_TAX_PER_YEAR'] = road_tax_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'ROAD_TAX_PER_YEAR'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'TRANSMISSION'] = transmission_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'TRANSMISSION'] = np.nan\n",
    "\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'DEREG_VALUE_FROM_SCRAPE_DATE'] = dereg_value_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'DEREG_VALUE_FROM_SCRAPE_DATE'] = np.nan\n",
    "        \n",
    "    df.loc[i, 'SCRAPE_DATE'] = datetime.now().strftime(\"%d/%m/%Y\")\n",
    "    \n",
    "    try:\n",
    "        df.loc[i, 'OMV'] = omv_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'OMV'] = np.nan\n",
    "\n",
    "    try:\n",
    "        df.loc[i, 'ARF'] = arf_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'ARF'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'COE_FROM_SCRAPE_DATE'] = coe_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'COE_FROM_SCRAPE_DATE'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'DAYS_OF_COE_LEFT'] = days_of_coe_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'DAYS_OF_COE_LEFT'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'ENGINE_CAPACITY_CC'] = engine_capacity_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'ENGINE_CAPACITY_CC'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'CURB_WEIGHT_KG'] = curb_weight_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'CURB_WEIGHT_KG'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'NO_OF_OWNERS'] = number_of_owners_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'NO_OF_OWNERS'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'VEHICLE_TYPE'] = type_of_vehicle_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'VEHICLE_TYPE'] = np.nan\n",
    "        \n",
    "    df.to_csv(\"{}.csv\".format(filename))    \n",
    "        \n",
    "    i += 1 # Allows next car listing to be put into a next row in the dataframe\n",
    "    time.sleep(1)  # Prevents us from getting locked out of the website\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('sgcarmart_used_cars_prices.csv',index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.now().strftime(\"%d/%m/%Y, %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_scraper4_shorter_time(input_listing_url):\n",
    "    \"\"\"Accepts a list of individual car listing urls and returns variables of importance for linear regression analysis.\n",
    "    ---\n",
    "    Input: List of urls\n",
    "    Output: Variables\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parsing an individual car listing url\n",
    "    response = requests.get(input_listing_url)\n",
    "    listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    \n",
    "    i = 0 # Indexing rows in the DF\n",
    "    \n",
    "       \n",
    "    # Retrieval functions to pull data from the Individual Listings after they have been parsed\n",
    "    df.loc[i, 'LISTING_URL'] = listing_url\n",
    "    df.loc[i, 'BRAND'] = brand_retrieval(listing_url)\n",
    "    df.loc[i, 'PRICE'] = price_retrieval(listing_url)\n",
    "    try:\n",
    "        df.loc[i, 'DEPRE_VALUE_PER_YEAR'] = depreciation_value_per_year_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'DEPRE_VALUE_PER_YEAR'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'REG_DATE'] = registered_date_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'REG_DATE'] = np.nan\n",
    "    \n",
    "    try:\n",
    "        df.loc[i, 'MILEAGE_KM'] = mileage_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'MILEAGE_KM'] = np.nan\n",
    "    \n",
    "    try:\n",
    "        df.loc[i, 'MANUFACTURED_YEAR'] = manufactured_year_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'MANUFACTURED_YEAR'] = np.nan\n",
    "    \n",
    "    try:\n",
    "        df.loc[i, 'ROAD_TAX_PER_YEAR'] = road_tax_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'ROAD_TAX_PER_YEAR'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'TRANSMISSION'] = transmission_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'TRANSMISSION'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'DEREG_VALUE_FROM_SCRAPE_DATE'] = dereg_value_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'DEREG_VALUE_FROM_SCRAPE_DATE'] = np.nan\n",
    "        \n",
    "    df.loc[i, 'SCRAPE_DATE'] = datetime.now().strftime(\"%d/%m/%Y\")\n",
    "    \n",
    "    try:\n",
    "        df.loc[i, 'OMV'] = omv_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'OMV'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'ARF'] = arf_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'ARF'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'COE_FROM_SCRAPE_DATE'] = coe_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'COE_FROM_SCRAPE_DATE'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'DAYS_OF_COE_LEFT'] = days_of_coe_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'DAYS_OF_COE_LEFT'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'ENGINE_CAPACITY_CC'] = engine_capacity_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'ENGINE_CAPACITY_CC'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'CURB_WEIGHT_KG'] = curb_weight_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'CURB_WEIGHT_KG'] = np.nan\n",
    "    try:\n",
    "        df.loc[i, 'NO_OF_OWNERS'] = number_of_owners_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'NO_OF_OWNERS'] = np.nan\n",
    "    try:\n",
    "        df.loc[i, 'VEHICLE_TYPE'] = type_of_vehicle_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'VEHICLE_TYPE'] = np.nan\n",
    "        \n",
    "        \n",
    "        \n",
    "    i += 1 # Allows next car listing to be put into a next row in the dataframe\n",
    "    time.sleep(2)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_scraper(listing_url_list):\n",
    "    \"\"\"Accepts a list of individual car listing urls and returns variables of importance for linear regression analysis.\n",
    "    ---\n",
    "    Input: List of urls\n",
    "    Output: Variables\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieval functions\n",
    "    print(f\"Brand: {brand_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Price: {price_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Depreciation Value Per Year: {depreciation_value_per_year_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Registered Date: {registered_date_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Mileage (km): {mileage_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Manufactured Year: {manufactured_year_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Road Tax Per Year:{road_tax_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Transmission: {transmission_retrieval(listing_url)}\\n\")\n",
    "    print(\"Dereg Value as of {}: {}\".format(datetime.now().strftime(\"%d/%m/%Y, %H:%M:%S\"),\n",
    "                                            dereg_value_retrieval(listing_url)))\n",
    "    print(f\"OMV: {omv_retrieval(listing_url)}\\n\")\n",
    "    print(f\"ARF: {arf_retrieval(listing_url)}\\n\")\n",
    "    print(f\"COE as of Today: {coe_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Days of COE Left: {days_of_coe_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Engine Capacity (CC):{ engine_capacity_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Curb Weight (kg): {curb_weight_retrieval(listing_url)}\\n\")\n",
    "    print(f\"# Of Owners: {number_of_owners_retrieval(listing_url)}\\n\")\n",
    "    print(f\"Vehicle Type:{type_of_vehicle_retrieval(listing_url)}\\n\")\n",
    "                                        \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_scraper2(listing_url_list):\n",
    "    \"\"\"Accepts a list of individual car listing urls and returns variables of importance for linear regression analysis.\n",
    "    ---\n",
    "    Input: List of urls\n",
    "    Output: Variables\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    # Retrieval functions\n",
    "    df.loc[i, 'LISTING_URL'] = listing_url\n",
    "    df.loc[i, 'BRAND'] = brand_retrieval(listing_url)\n",
    "    df.loc[i, 'PRICE'] = price_retrieval(listing_url)\n",
    "    df.loc[i, 'DEPRE_VALUE_PER_YEAR'] = depreciation_value_per_year_retrieval(listing_url)\n",
    "    df.loc[i, 'REG_DATE'] = registered_date_retrieval(listing_url)\n",
    "    df.loc[i, 'MILEAGE_KM'] = mileage_retrieval(listing_url)\n",
    "    df.loc[i, 'MANUFACTURED_YEAR'] = manufactured_year_retrieval(listing_url)\n",
    "    df.loc[i, 'ROAD_TAX_PER_YEAR'] = road_tax_retrieval(listing_url)\n",
    "    df.loc[i, 'TRANSMISSION'] = transmission_retrieval(listing_url)\n",
    "    df.loc[i, 'DEREG_VALUE_FROM_SCRAPE_DATE'] = dereg_value_retrieval(listing_url)\n",
    "    df.loc[i, 'SCRAPE_DATE'] = datetime.now().strftime(\"%d/%m/%Y\")\n",
    "    df.loc[i, 'OMV'] = omv_retrieval(listing_url)\n",
    "    df.loc[i, 'ARF'] = arf_retrieval(listing_url)\n",
    "    df.loc[i, 'COE_FROM_SCRAPE_DATE'] = coe_retrieval(listing_url)\n",
    "    df.loc[i, 'DAYS_OF_COE_LEFT'] = days_of_coe_retrieval(listing_url)\n",
    "    df.loc[i, 'ENGINE_CAPACITY_CC'] = engine_capacity_retrieval(listing_url)\n",
    "    df.loc[i, 'CURB_WEIGHT_KG'] = curb_weight_retrieval(listing_url)\n",
    "    try:\n",
    "        df.loc[i, 'NO_OF_OWNERS'] = number_of_owners_retrieval(listing_url)\n",
    "    except ValueError:\n",
    "        df.loc[i, 'NO_OF_OWNERS'] = np.nan\n",
    "    df.loc[i, 'VEHICLE_TYPE'] = type_of_vehicle_retrieval(listing_url)\n",
    "                                        \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_scraper3(listing_url_list):\n",
    "    \"\"\"Accepts a list of individual car listing urls and returns variables of importance for linear regression analysis.\n",
    "    ---\n",
    "    Input: List of urls\n",
    "    Output: Variables\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    # Retrieval functions\n",
    "    df.loc[i, 'LISTING_URL'] = listing_url\n",
    "    df.loc[i, 'BRAND'] = brand_retrieval(listing_url)\n",
    "    df.loc[i, 'PRICE'] = price_retrieval(listing_url)\n",
    "    try:\n",
    "        df.loc[i, 'DEPRE_VALUE_PER_YEAR'] = depreciation_value_per_year_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'DEPRE_VALUE_PER_YEAR'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'REG_DATE'] = registered_date_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'REG_DATE'] = np.nan\n",
    "    \n",
    "    try:\n",
    "        df.loc[i, 'MILEAGE_KM'] = mileage_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'MILEAGE_KM'] = np.nan\n",
    "    \n",
    "    try:\n",
    "        df.loc[i, 'MANUFACTURED_YEAR'] = manufactured_year_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'MANUFACTURED_YEAR'] = np.nan\n",
    "    \n",
    "    try:\n",
    "        df.loc[i, 'ROAD_TAX_PER_YEAR'] = road_tax_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'ROAD_TAX_PER_YEAR'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'TRANSMISSION'] = transmission_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'TRANSMISSION'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'DEREG_VALUE_FROM_SCRAPE_DATE'] = dereg_value_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'DEREG_VALUE_FROM_SCRAPE_DATE'] = np.nan\n",
    "        \n",
    "    df.loc[i, 'SCRAPE_DATE'] = datetime.now().strftime(\"%d/%m/%Y\")\n",
    "    \n",
    "    try:\n",
    "        df.loc[i, 'OMV'] = omv_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'OMV'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'ARF'] = arf_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'ARF'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'COE_FROM_SCRAPE_DATE'] = coe_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'COE_FROM_SCRAPE_DATE'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'DAYS_OF_COE_LEFT'] = days_of_coe_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'DAYS_OF_COE_LEFT'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'ENGINE_CAPACITY_CC'] = engine_capacity_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'ENGINE_CAPACITY_CC'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'CURB_WEIGHT_KG'] = curb_weight_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'CURB_WEIGHT_KG'] = np.nan\n",
    "    try:\n",
    "        df.loc[i, 'NO_OF_OWNERS'] = number_of_owners_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'NO_OF_OWNERS'] = np.nan\n",
    "    try:\n",
    "        df.loc[i, 'VEHICLE_TYPE'] = type_of_vehicle_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'VEHICLE_TYPE'] = np.nan\n",
    "                                        \n",
    "                                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
